{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['image-name'] = os.listdir('../data/flowers/')\n",
    "data['species'] = data['image-name'].apply(lambda x: int(x[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### opening images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_images_flatten = np.array([plt.imread('../data/flowers/'+img).ravel() for img in data['image-name'].tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### applying pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dim(imgs, k):\n",
    "    pca = PCA(n_components=k)\n",
    "    return pca.fit_transform(imgs)\n",
    "\n",
    "images_600 = reduce_dim(raw_images_flatten, 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using a neural network to create a better mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, concatenate,  Dropout, Conv2D, MaxPool2D\n",
    "\n",
    "input_image = Input(shape=(128, 128, 4))\n",
    "x = Conv2D(32, (3, 3), activation='relu')(input_image)\n",
    "x = MaxPool2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = MaxPool2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu')(x)\n",
    "x = MaxPool2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "base_network = Model(inputs=input_image, outputs=x)\n",
    "\n",
    "\n",
    "input_image_one = Input(shape=(128, 128, 4), name='input_image_one') # input layer for image one\n",
    "input_image_two = Input(shape=(128, 128, 4), name='input_image_two') # input layer for image two\n",
    "concat_layer = concatenate([base_network(input_image_one), base_network(input_image_two)])\n",
    "x = Dense(32)(concat_layer)\n",
    "similarity = Dense(1, activation='sigmoid')(x) # similar or not\n",
    "\n",
    "model = Model(inputs=[input_image_one, input_image_two],\n",
    "            outputs=similarity)\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image_one (InputLayer)    [(None, 128, 128, 4) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_image_two (InputLayer)    [(None, 128, 128, 4) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 64)           107384      input_image_one[0][0]            \n",
      "                                                                 input_image_two[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128)          0           model[0][0]                      \n",
      "                                                                 model[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           4128        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            33          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 111,545\n",
      "Trainable params: 111,545\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reduced = data.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_input = []\n",
    "second_input = []\n",
    "labels = []\n",
    "for i, img_one in enumerate(data_reduced['image-name'].to_list()):\n",
    "    for j, img_two in enumerate(data_reduced['image-name'].to_list()):\n",
    "        \n",
    "        if j > i:\n",
    "            first_input.append(plt.imread('../data/flowers/'+img_one))\n",
    "            second_input.append(plt.imread('../data/flowers/'+img_two))\n",
    "            s = 0 if img_one[:2] != img_two[:2] else 1\n",
    "            labels.append(s)\n",
    "\n",
    "first_input = np.array(first_input)\n",
    "second_input = np.array(second_input)  \n",
    "labels = np.array(labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "155/155 [==============================] - 36s 231ms/step - loss: 0.2934\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 35s 228ms/step - loss: 0.2307\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 35s 228ms/step - loss: 0.2333\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 35s 227ms/step - loss: 0.2164\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 35s 228ms/step - loss: 0.2365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f340b9333d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([first_input, second_input], labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_images = np.array([plt.imread('../data/flowers/'+img) for img in data['image-name'].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 1.1384286 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.19039662,\n",
       "       0.        , 0.        , 0.07191174, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.04242852, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.21581745, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.8016604 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.7161391 , 0.9376043 , 0.        , 0.7023733 ,\n",
       "       0.        , 0.7692271 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_network.predict(raw_images)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
