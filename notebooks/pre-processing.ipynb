{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset that contains images' path and label\n",
    "data = pd.DataFrame()\n",
    "data['image-name'] = os.listdir('../data/flowers/')\n",
    "\n",
    "# extracting species\n",
    "data['species'] = data['image-name'].apply(lambda x: int(x[:2]))\n",
    "\n",
    "# saving \"true\" label\n",
    "np.save('../data/true_label.npy', data['species'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_images_flatten = np.array([plt.imread('../data/flowers/'+img).ravel() for img in data['image-name'].tolist()])\n",
    "# saving raw images\n",
    "np.save('../data/raw_images_flatten.npy', raw_images_flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### applying pca to reduce images' dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dim(imgs, k):\n",
    "    pca = PCA(n_components=k)\n",
    "    return pca.fit_transform(imgs)\n",
    "\n",
    "images_600 = reduce_dim(raw_images_flatten, 600)\n",
    "# saving reduced images\n",
    "np.save('../data/images_600.npy', images_600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using a neural network to create a better mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, concatenate,  Dropout, Conv2D, MaxPool2D\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# embeddings size\n",
    "EMBED_SIZE = 128\n",
    "\n",
    "input_image = Input(shape=(128, 128, 4))\n",
    "x = Conv2D(32, (3, 3), activation='relu')(input_image)\n",
    "x = MaxPool2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = MaxPool2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu')(x)\n",
    "x = MaxPool2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(EMBED_SIZE, activation='relu')(x)\n",
    "\n",
    "base_network = Model(inputs=input_image, outputs=x)\n",
    "\n",
    "def triplet_loss(y_true, y_pred):\n",
    "    anchor, positive, negative = y_pred[:,:EMBED_SIZE], y_pred[:,EMBED_SIZE:2*EMBED_SIZE], y_pred[:,2*EMBED_SIZE:]\n",
    "    positive_dist = tf.reduce_mean(tf.square(anchor - positive), axis=1)\n",
    "    negative_dist = tf.reduce_mean(tf.square(anchor - negative), axis=1)\n",
    "    return tf.maximum(positive_dist - negative_dist + 0.2, 0.)\n",
    "\n",
    "input_image_one = Input(shape=(128, 128, 4), name='input_image_one') # input layer for image one\n",
    "input_image_two = Input(shape=(128, 128, 4), name='input_image_two') # input layer for image two\n",
    "input_image_three = Input(shape=(128, 128, 4), name='input_image_three') # input layer for image three\n",
    "\n",
    "out = concatenate([base_network(input_image_one), base_network(input_image_two),\n",
    "                             base_network(input_image_three)])\n",
    "\n",
    "model = Model(inputs=[input_image_one, input_image_two, input_image_three],\n",
    "            outputs=out)\n",
    "model.compile(loss=triplet_loss, optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some utils\n",
    "\n",
    "def find_positive(df, l):\n",
    "    \n",
    "    \"\"\"\n",
    "        Find one example of l class.\n",
    "    \"\"\"\n",
    "    \n",
    "    positive = df[df['species'] == l].sample(1)['image-name'].iloc[0]\n",
    "    return plt.imread('../data/flowers/'+positive)\n",
    "    \n",
    "def find_negative(df, l):\n",
    "    \n",
    "    \"\"\"\n",
    "        Find one example different from l class.\n",
    "    \"\"\"\n",
    "    \n",
    "    negative = df[df['species'] != l].sample(1)['image-name'].iloc[0]\n",
    "    return plt.imread('../data/flowers/'+negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a oversized dataset - because there is a random process in the training step\n",
    "data = data.sample(3500, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the training instances\n",
    "# instance = one image + one similar image (same label) + one different image (different label)\n",
    "\n",
    "A = []\n",
    "P = []\n",
    "N = []\n",
    "\n",
    "for img, species in zip(data['image-name'].tolist(), data['species'].tolist()):\n",
    "    \n",
    "    A.append(plt.imread('../data/flowers/'+img))\n",
    "    P.append(find_positive(data, species))\n",
    "    N.append(find_negative(data, species))\n",
    "    \n",
    "A = np.array(A)\n",
    "P = np.array(P)\n",
    "N = np.array(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "110/110 [==============================] - 40s 355ms/step - loss: 0.1237\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 40s 360ms/step - loss: 0.0722\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 37s 340ms/step - loss: 0.0521\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 38s 344ms/step - loss: 0.0312\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 37s 340ms/step - loss: 0.0204\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 37s 335ms/step - loss: 0.0134\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 38s 343ms/step - loss: 0.0101\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 37s 341ms/step - loss: 0.0073\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 38s 349ms/step - loss: 0.0065\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 37s 338ms/step - loss: 0.0054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff4e49e2460>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "model.fit([A, P, N], np.zeros((data.shape[0], 3 * EMBED_SIZE)), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_images = np.array([plt.imread('../data/flowers/'+img) for img in data['image-name'].tolist()])\n",
    "# creating embeddings for each image\n",
    "embeddings = base_network.predict(raw_images)\n",
    "# saving embeddings' images\n",
    "np.save('../data/embeddings.npy', embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
